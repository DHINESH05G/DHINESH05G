{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recognition_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvE8VR4tPtJO"
      },
      "outputs": [],
      "source": [
        "#importing necessary packages\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import random\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_list = []\n",
        "class_list = []\n",
        "IMG_SIZE = 50 # The size of images the network will work on"
      ],
      "metadata": {
        "id": "ZA37rM2pPyjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#All the categories that should be detect in neural network \n",
        "\n",
        "CATEGORIES = [] \n",
        "ignore_files = ['1 - Multipart','2 - Unknown'] #This files/folder should not include in neural network\n",
        "DATADIR = r'path_to\\Labelled Dataset - Fig 51'\n",
        "for directoryfile in os.listdir(DATADIR):\n",
        "    if(directoryfile in ignore_files):\n",
        "        continue\n",
        "    CATEGORIES.append(directoryfile) #Append all the character's name as label in 'CATEGORIES'\n",
        "print(len(CATEGORIES))"
      ],
      "metadata": {
        "id": "dANWJjCVPyoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = []\n",
        "\n",
        "def create_training_data():\n",
        "    for category in CATEGORIES :\n",
        "        path = os.path.join(DATADIR, category)\n",
        "        class_num = CATEGORIES.index(category) # Charcater's name label as class number \n",
        "        for img in os.listdir(path):\n",
        "            try :\n",
        "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE) # Converting image into grayscale\n",
        "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE)) #Resizing all images into same size (50,50)\n",
        "                training_data.append([new_array, class_num]) # append all images with their respective class name\n",
        "            except Exception as e:\n",
        "                print(path)\n",
        "                pass\n",
        "\n",
        "create_training_data()"
      ],
      "metadata": {
        "id": "1UofByhqPyrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Storing features in X and labels in Y using numpy\n",
        "\n",
        "random.shuffle(training_data)\n",
        "X = [] #features\n",
        "y = [] #labels\n",
        "\n",
        "for features, label in training_data:\n",
        "    X.append(features)\n",
        "    y.append(label)\n",
        "\n",
        "\n",
        "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)"
      ],
      "metadata": {
        "id": "qpjF1317Pyvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving features and label in pickle files\n",
        "\n",
        "pickle_out = open(\"X.pickle\", \"wb\")\n",
        "pickle.dump(X, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open(\"y.pickle\", \"wb\")\n",
        "pickle.dump(y, pickle_out)\n",
        "pickle_out.close()"
      ],
      "metadata": {
        "id": "rgtG1Y6CPyzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_data)"
      ],
      "metadata": {
        "id": "mWSWDhPUPy2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iHGcMd3_Py5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3KyKqhoBPy8p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}